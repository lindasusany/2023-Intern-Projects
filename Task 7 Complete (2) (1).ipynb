{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0441c647-17d6-4238-88e3-dcdc46ef8459",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e674363-2469-4306-82d4-471f0708df6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6cc136b-6300-42f6-9b3e-71437b02b3dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28c39201-7c43-4f52-a612-4fd409e16a1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b9b6809-8f65-4cf1-960c-25dae4e7e728",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ecb0bd8-8541-4796-9691-ff14bbdb26de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59b8a8d2-719d-48ac-af88-b716c92d9ebe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4ec2d47-76f2-4536-a108-e1e7be7c2148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c596d469-7c9c-47e5-b2c0-aa07370b447f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when,current_date, expr,mean,col, sum as spark_sum,count,avg\n",
    "from pyspark.sql.types import DoubleType,IntegerType,StringType,NumericType\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, Imputer, VectorAssembler\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from h2o.automl import H2OAutoML\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#import h2o\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51c81a54-f10a-4285-b192-d67e8a279cb8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d688c10-f569-4be6-b33e-e8238860a934",
     "showTitle": true,
     "title": "Import data (Sharepoint Trail - Fail)"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "sharepoint_url = 'https://cmhcschl.sharepoint.com/:x:/s/FinancingOperation-Legacyteam-SupportandInnovationteam/EZA0yVuxjzJCoqM4DJvoohkBJVCYqbPQ6x2jExfTbuCfug?e=4%3AGfYMdr&at=9&CID=2C9A02A9-E602-46FA-B712-CB50AEDFEAB4&wdLOR=c7117F0A1-54E1-463B-AC5F-489B07B48987'\n",
    "\n",
    "# Send a GET request to download the file\n",
    "response = requests.get(sharepoint_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Read the Excel file into a pandas DataFrame\n",
    "    df = pd.read_excel(response.content)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "    print(df.head())\n",
    "else:\n",
    "    # Display an error message if the download failed\n",
    "    print(\"Failed to download the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4da31ade-2575-4751-bc89-0e860d41fd9a",
     "showTitle": true,
     "title": "Import Data(Manually)"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"/Workspace/Users/zzhang@cmhc-schl.gc.ca/TimeStudy-2023Jun.xlsx\"  # Update the folder path as per your directory structure\n",
    "TS = pd.read_excel(folder_path,sheet_name = 'Advancing Data',header=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9f80a01-f613-43c4-a1a2-d4d8af381278",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e82c8846-aa6a-420c-80a2-c3e12698c27a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8949b81-d4c4-4f9e-a92f-f67f2e1886cb",
     "showTitle": true,
     "title": "Impute Missing Values"
    }
   },
   "outputs": [],
   "source": [
    "TS_c = TS.fillna(0,inplace=False)\n",
    "TS_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13da111d-4765-43ce-be4f-7ef5bab928f4",
     "showTitle": true,
     "title": "Let's see how many samples we get here"
    }
   },
   "outputs": [],
   "source": [
    "TS_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9fbabf1-f817-4fd7-8e25-75440fc0aba6",
     "showTitle": true,
     "title": "Transform Categorical Columns to Numerical"
    }
   },
   "outputs": [],
   "source": [
    "#is there any categorical columns?\n",
    "TS_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63c1bb74-83aa-437f-824e-afa84a8d692e",
     "showTitle": true,
     "title": "Test and Drop Duplication !!!Is this step necessary?"
    }
   },
   "outputs": [],
   "source": [
    "TS_c.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e635684b-d054-4687-bc62-25c5c80f4d51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TS_mask = TS_c.duplicated()\n",
    "if TS_mask.any():\n",
    "    TS_c = TS_c[~TS_mask]\n",
    "TS_c.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "892cc8ff-2131-4887-8a75-a62285471187",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f9c79b9-652b-402c-ac2a-69b22f934801",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TS_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed9197a0-deae-4907-af37-b775af4ed978",
     "showTitle": true,
     "title": "Categorical Variables Occurences"
    }
   },
   "outputs": [],
   "source": [
    "for col in TS_c.columns:\n",
    "    if TS_c[col].dtype == 'object':\n",
    "        counts = TS_c[col].value_counts()\n",
    "        print(f\"Value Counts for '{col}' is :\")\n",
    "        print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4b19f4d-7df2-4f9b-be8e-bdd11f993ee2",
     "showTitle": true,
     "title": "Visualize Categorical Cols with High Cardinality"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of 'Total Minutes' for each staff in each collection period\n",
    "staff_sum_df = TS_c.groupby(['Staff Name:', 'Collection Period:'])['Total Minutes:'].sum().reset_index()\n",
    "\n",
    "# Convert the sum of 'Total Minutes' to hours by dividing by 60 and round to two decimal places\n",
    "staff_sum_df['Total Minutes:'] = (staff_sum_df['Total Minutes:'] / 60).round(2)\n",
    "\n",
    "# Calculate the overall average of 'Total Minutes' across all staff and all collection periods\n",
    "overall_avg_minutes = TS_c.groupby('Collection Period:')['Total Minutes:'].mean() / 60  # Convert to hours and calculate mean\n",
    "\n",
    "# Create the Plotly bar plot\n",
    "fig = px.bar(staff_sum_df, x='Staff Name:', y='Total Minutes:', color='Staff Name:',\n",
    "             color_continuous_scale='Viridis',\n",
    "             labels={'Total Minutes:': 'Total Hours (Sum)', 'Staff Name:': 'Staff Name', 'Collection Period:': 'Month'},\n",
    "             title='Total Hours per Staff by Collection Period',\n",
    "             text='Total Minutes:',\n",
    "             facet_row='Collection Period:')\n",
    "\n",
    "# Add a line trace for the overall average\n",
    "fig.add_shape(type='line',\n",
    "              x0=-0.5, x1=len(staff_sum_df['Staff Name:']) - 0.5,\n",
    "              y0=overall_avg_minutes, y1=overall_avg_minutes,\n",
    "              line=dict(color='red', width=2))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(xaxis_tickangle=-45, xaxis_title='Staff Name', yaxis_title='Total Hours', showlegend=False, height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3235503-7506-43e6-8460-dcfc57e87c6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of 'Total Minutes' for each staff in each collection period\n",
    "staff_sum_df = TS_c.groupby([\"Program:\", 'Collection Period:'])['Total Minutes:'].mean().reset_index()\n",
    "\n",
    "# Convert the sum of 'Total Minutes' to hours by dividing by 60 and round to two decimal places\n",
    "staff_sum_df['Average Minutes:'] = (staff_sum_df['Total Minutes:'] / 60).round(2)\n",
    "\n",
    "# Create the Plotly bar plot\n",
    "fig = px.bar(staff_sum_df, x='Program:', y='Total Minutes:', color='Program:',\n",
    "             color_continuous_scale='Viridis',\n",
    "             labels={'Total Minutes:': 'Total Hours (Sum)', 'Program:': 'Program', 'Collection Period:': 'Month'},\n",
    "             title='Total Hours per Program by Collection Period',\n",
    "             text='Total Minutes:',\n",
    "             facet_row='Collection Period:')\n",
    "\n",
    "# Add a line trace for the overall average\n",
    "fig.add_shape(type='line',\n",
    "              x0=-0.5, x1=len(staff_sum_df['Program:']) - 0.5,\n",
    "              y0=overall_avg_minutes, y1=overall_avg_minutes,\n",
    "              line=dict(color='red', width=2))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(xaxis_tickangle=-45, xaxis_title='Program', yaxis_title='Total Hours', showlegend=False, height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11c6b579-d7cd-49c4-ad60-0a13f4fad836",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Calculate the sum of 'Total Minutes' for each staff in each program\n",
    "staff_sum_df = TS_c.groupby([\"Program:\"])['Total Minutes:'].mean().reset_index()\n",
    "\n",
    "# Convert the sum of 'Total Minutes' to hours by dividing by 60 and round to two decimal places\n",
    "staff_sum_df['Total Hours (Sum)'] = (staff_sum_df['Total Minutes:'] / 60).round(2)\n",
    "\n",
    "# Create the Plotly bar plot\n",
    "fig = px.bar(staff_sum_df, x='Program:', y='Total Hours (Sum)', color='Program:',\n",
    "             color_continuous_scale='Viridis',\n",
    "             labels={'Total Hours (Sum)': 'Total Hours (Sum)', 'Program:': 'Program'},\n",
    "             text='Total Minutes:',\n",
    "             title='Total Hours Spent by Program')\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(xaxis_tickangle=-45, xaxis_title='Program', yaxis_title='Total Hours (Sum)', showlegend=False, height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c119d173-9255-4e20-8d04-6e032484f506",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#base on time it takes for program, compare the average of each program and individual/ \n",
    "#compare the time they spent one advancing and the rest of their time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5bb04c3-a5de-4175-a4b5-223bb03d646f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_histogram,facet_grid,theme,element_text,geom_text,ylab\n",
    "print(ggplot(TS_c)+aes(x=\"Staff Name:\")+ylab(\"Num of Advancing Sloven\")+geom_histogram(binwidth=0.5)+facet_grid(facets='~Collection Period:')+theme(axis_text_x=element_text(angle=45, ha='right',size=6))+geom_text(aes(label='stat(count)'), stat='count', va='bottom', format_string=\"{:.0f}\",size=5))\n",
    "#make the pic larger\n",
    "#distinguish the owner and creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25d949a2-c93b-4152-a171-3e0127433dc9",
     "showTitle": true,
     "title": "Data Transformation"
    }
   },
   "outputs": [],
   "source": [
    "#Uniform values in \"Stage\" and 'Budget type\" by lowercasing certain letters\n",
    "# Convert the values in \"Stage\" column to lowercase\n",
    "TS_c['Stage:'] = TS_c['Stage:'].str.lower()\n",
    "TS_c['Budget Type:'] = TS_c['Budget Type:'].str.lower()\n",
    "TS_c['Program:'] = TS_c['Program:'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1c433d1-3378-43cc-9881-6c190e86867a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "TS_c['Stage:'].value_counts()\n",
    "TS_c['Budget Type:'].value_counts()\n",
    "TS_c['Program:'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60f0df51-7eb9-4d01-951a-8766a44ab716",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count the occurrences of each \"CRM File #\" and create a new column \"CRM File # Count\"\n",
    "TS_c['CRM File # Count'] = TS_c.groupby('CRM File #:')['CRM File #:'].transform('count')\n",
    "\n",
    "# Set rows where \"CRM File #\" occurs less than 3 as \"other\"\n",
    "TS_c.loc[TS_c['CRM File # Count'] < 15, 'CRM File #:'] = 'other'\n",
    "\n",
    "# Drop the temporary \"CRM File # Count\" column if you don't need it anymore\n",
    "TS_c.drop(columns=['CRM File # Count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3378a32f-4184-43b5-b12a-e114920f9cc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TS_c['CRM File #:'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b727682f-b298-418f-b060-cc7cfe4e9f9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_values_count = TS_c['Program:'].nunique()\n",
    "print(\"Number of unique values:\", unique_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b723acc4-3d4a-459b-b469-3dd0c21311b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create dummy variables for the \"Budget Type\" column\n",
    "dummy_budget_type = pd.get_dummies(TS_c['Budget Type:'])\n",
    "\n",
    "# Keep both \"contribution/forgiveable loan\" and \"repayable loan\" columns\n",
    "dummy_budget_type = dummy_budget_type[['both (contribution/forgiveable loan & repayable loan)', 'repayable loan']]\n",
    "\n",
    "# Concatenate the dummy variables back to the original DataFrame\n",
    "TS_c = pd.concat([TS_c, dummy_budget_type], axis=1)\n",
    "\n",
    "# Drop the original \"Budget Type\" column\n",
    "TS_c.drop('Budget Type:', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e153215-6f83-49a6-8ea1-e656ea321a44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd_con = TS_c['Program:'].str.get_dummies().drop('federal lands initiative (fli)', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4caecd7e-40b0-4716-9823-fcce8e416d0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd_con = pd_con.add_prefix('Program:_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb1114da-5d9e-44f7-a3d9-8dc2e8f2344f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TS_c_dropped = TS_c.drop(columns=['Program:'])\n",
    "\n",
    "# Get dummies for the DataFrame after dropping the 'Program:' column\n",
    "TS_f = pd.get_dummies(TS_c_dropped, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b42ac19-21b8-4f99-8f40-f145a523d846",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat([pd_con, TS_f], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0a25c6c-a2ce-4981-bfcb-65a153c3ce7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51ff8fae-09f8-4e57-aeb3-139f8d55722b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TS_f = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b5157b5-f51d-4d11-b17b-315e47bf6d45",
     "showTitle": true,
     "title": "Highly Correlated Var Test"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = TS_f.corr()\n",
    "\n",
    "# Set the threshold for high correlation (you can adjust this value as needed)\n",
    "threshold = 0.5\n",
    "\n",
    "# Initialize a list to store highly correlated variable pairs\n",
    "highly_correlated_pairs = []\n",
    "\n",
    "# Iterate through the correlation matrix and identify highly correlated variables\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        correlation = corr_matrix.iloc[i, j]\n",
    "        if abs(correlation) > threshold:\n",
    "            var1 = corr_matrix.columns[i]\n",
    "            var2 = corr_matrix.columns[j]\n",
    "            highly_correlated_pairs.append((var1, var2, correlation))\n",
    "\n",
    "# Print the highly correlated variable pairs\n",
    "if highly_correlated_pairs:\n",
    "    print(\"Highly correlated variable pairs:\")\n",
    "    for pair in highly_correlated_pairs:\n",
    "        var1, var2, correlation = pair\n",
    "        print(f\"{var1} and {var2}: {correlation:.2f}\")\n",
    "else:\n",
    "    print(\"No highly correlated variables found.\")\n",
    "    #keep activity phase and program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cee4262-5873-4032-b564-a6d211b0fddd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop the columns using a range of column names\n",
    "TS_f.drop(columns=TS_f.loc[:, 'Time Record #1':'Time Record #10'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6115a91f-60ef-4c8c-91fe-b13c7c5f5f23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TS_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "296c4fa2-0bb2-4a7a-a3ba-0b1710931bab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TS_f= TS_f.drop(columns=['repayable loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa0a4e02-4cd0-4c7f-a01f-2338a54d900f",
     "showTitle": true,
     "title": "Split Test and Train Data Set"
    }
   },
   "outputs": [],
   "source": [
    "# Split your data into training and testing sets\n",
    "y = TS_f['Total Minutes:']\n",
    "X = TS_f.drop('Total Minutes:',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59835882-930c-4ad4-a06e-f61b55813a7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc4d7996-082f-4ac6-a5c1-1053db748d7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ecee829-0278-41a7-80a5-4ad941cb5c7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize H2O and start the H2O server\n",
    "h2o.init()\n",
    "\n",
    "# Convert the pandas DataFrames to H2O DataFrames\n",
    "train_data = h2o.H2OFrame(pd.concat([X_train, y_train], axis=1))\n",
    "test_data = h2o.H2OFrame(pd.concat([X_test, y_test], axis=1))\n",
    "\n",
    "# Specify the name of the target variable\n",
    "target_variable = 'Total Minutes'\n",
    "\n",
    "# Run AutoML regression\n",
    "aml = H2OAutoML(max_runtime_secs=120)\n",
    "aml.train(y=target_variable, training_frame=train_data)\n",
    "\n",
    "# Get the best model from AutoML\n",
    "best_model = aml.leader\n",
    "\n",
    "y_test_pred = best_model.predict(test_data).as_data_frame().values.flatten()\n",
    "\n",
    "y_test_pred = np.array(y_test_pred)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"Test R-squared: {test_r2:.2f}\")\n",
    "\n",
    "# Visualize the comparison of forecast and actual values for both training and test sets\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(y_test, y_test_pred, color='orange', alpha=0.5, label='Test Data')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2)\n",
    "plt.xlabel(\"Actual Values (Test)\")\n",
    "plt.ylabel(\"Predicted Values (Test)\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Forecast and Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c487682c-bf36-4dd2-a77f-312be9b30bab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from autosklearn.regression import AutoSklearnRegressor\n",
    "# Create the AutoML regression model\n",
    "automl_regressor = AutoSklearnRegressor(time_left_for_this_task=120, per_run_time_limit=30)\n",
    "\n",
    "# Fit the model to the training data\n",
    "automl_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = automl_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d7f490e-1198-4e82-b5ec-776215d0abe5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define a dictionary to store the models and their corresponding RMSEs\n",
    "models = {\n",
    "     'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Support Vector Machine': SVR(),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    #'LightGBM': LGBMRegressor(),\n",
    "    'CatBoost': CatBoostRegressor(logging_level='Silent'),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'MLP Neural Network': MLPRegressor(),\n",
    "    'AdaBoost': AdaBoostRegressor(),\n",
    "    'Elastic Net': ElasticNet()\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "# Loop through each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"{name} RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    # Update the best model if this model has a lower RMSE\n",
    "    if rmse < best_rmse:\n",
    "        best_model = model\n",
    "        best_rmse = rmse\n",
    "\n",
    "print(f\"Best Model: {best_model.__class__.__name__} with RMSE: {best_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1e3f24c-bbb8-4168-b233-8df6d8a878b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the best model on the entire data (train + test)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the predicted values for the entire data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_all = best_model.predict(X)\n",
    "# Create a DataFrame to store the actual and predicted values\n",
    "forecast_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "forecast_df.reset_index(drop=True, inplace=True)\n",
    "# Visualize the forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(forecast_df['Actual'], label='Actual', marker='o')\n",
    "plt.plot(forecast_df['Predicted'], label='Predicted', marker='x')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Total Minutes')\n",
    "plt.title('Optimal Forecast vs. Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08a4bf17-835c-4596-81e7-50519ea7238d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c8db73f-70b2-4826-920c-9a98233532f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "What is shap values?\n",
    "A machine learning model's prediction, f(x), can be represented as the sum of its computed SHAP values, plus a fixed base value, such that:\n",
    "f(x)=base_value+sum(SHAPvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5a928e3-8e97-4b95-bfb4-c011fa75d223",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For instance, we see that being in the prepare advance phase have positive SHAP values (the points extending towards the right are increasingly red) and not being in the prepare advance phase have negative SHAP values (the points extending towards the left are increasingly blue). This indicates that the prepare stage is most time consuming. The reverse is seen for Heather - Heather dealt with advanving in high efficiency.\n",
    "\n",
    "The distribution of points can also be informative. For prepare advance phase, we see a dense cluster of none prepare advance instances (blue points) with small but negative SHAP values. Instances of prepare advance (red points) extend further towards the right, suggesting being in the prepare stage has a stronger positive impact on processing time than the negative impact of not in the prepare phase on time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64f509cc-d3d3-4b4e-a831-cef1a870e85f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The beeswarm plot is designed to display an information-dense summary of how the top features in a dataset impact the model’s output. Each instance the given explanation is represented by a single dot on each feature fow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07b811ba-bb09-4a1d-8e8a-9f42b76798e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "# plot the distribution of importances for each feature over all samples\n",
    "shap.summary_plot(shap_values,X_test,plot_type='dot',plot_size=(20,10))\n",
    "feature_names = X_test.columns\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "cb_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "vals = np.abs(cb_resultX).values.mean(0)\n",
    "\n",
    "shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fee9358-49b0-48b6-a433-3fcad23f08e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create three separate DataFrames based on the conditions\n",
    "df_rhi2 = X[X[\"Program:_rapid housing initiative 2 (rhi2)\"] == True]\n",
    "df_semp = X[X[\"Program:_shared equity mortgage program (semp)\"] == True]\n",
    "df_innovation = X[X[\"Program:_innovation fund 2\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfcbe7d7-66dc-4a93-8a38-20d557f7f176",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(df_rhi2)\n",
    "feature_names = X_test.columns\n",
    "\n",
    "rhi_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "vals = np.abs(rhi_resultX).values.mean(0)\n",
    "shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['Factors','Importance'])\n",
    "shap_importance.sort_values(by=['Importance'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_filtered = shap_importance[shap_importance['Importance'] > 10]\n",
    "title = \"(Program:_rapid housing initiative 2 (rhi2)) Top Factors with Importance > 10\"\n",
    "print(title)\n",
    "print('-' * len(title))  # Add a line of dashes for separation\n",
    "shap_importance_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e9e2181-3ae9-4fe8-bab4-4d31ad9944f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(df_semp)\n",
    "feature_names = X_test.columns\n",
    "semp_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "vals = np.abs(semp_resultX).values.mean(0)\n",
    "shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['Factors','Importance'])\n",
    "shap_importance.sort_values(by=['Importance'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_filtered = shap_importance[shap_importance['Importance'] > 10]\n",
    "title = \"(Program:_shared equity mortgage program (semp)) Top Factors with Importance > 10\"\n",
    "print(title)\n",
    "print('-' * len(title))  # Add a line of dashes for separation\n",
    "shap_importance_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5255fe7-df1b-40f3-a379-a489f9d8c377",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(df_innovation)\n",
    "feature_names = X_test.columns\n",
    "inno_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "vals = np.abs(inno_resultX).values.mean(0)\n",
    "shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['Factors','Importance'])\n",
    "shap_importance.sort_values(by=['Importance'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance_filtered = shap_importance[shap_importance['Importance'] > 10]\n",
    "title = \"(Program:_innovation fund 2) Top Factors with Importance > 10\"\n",
    "print(title)\n",
    "print('-' * len(title))  # Add a line of dashes for separation\n",
    "shap_importance_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0972b6b-b3c2-4ddd-9117-01c1f202faa5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c35ae6d6-6a41-46ab-abcd-34c9397c134f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da66c5a8-cf9b-4091-8e30-bcfad2f6d401",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "A global feature importance plot, where the global importance of each feature is taken to be the mean absolute value for that feature over all the given samples.\n",
    "Belonging to N###, Being at the ### phase or portfolio management, being dealt with ### or ####, are prone to have longer processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d92fb2da-5d21-4f4a-98f6-9198b76a1eee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d97f03e-dd33-4d11-9c6b-237d559ee28f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Simulation involves creating a model or a representation of a real-world system or process to understand its behavior and evaluate different scenarios.\n",
    "Simulations are useful when the underlying system is complex, has uncertain variables, or lacks a closed-form analytical solution.\n",
    "Prediction involves estimating future outcomes or values based on historical data and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcff926d-c9ae-4103-b68c-d83d9323e613",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Import dataset\n",
    "PO = spark.table('crm_ah.msdyn_purchaseorder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b273afb2-35da-4be5-a1d2-17d51cd0a710",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(PO.select('msdyn_approvalstatus_en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a7b8fae-cdd9-44e9-993c-8241250cb610",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FS = spark.table('crm_shared_entity.cmhc_fundingsource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70e8fa32-2bd0-4ddc-bc8b-505cede0367a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FS = spark.table('crm_crosslob.cmhc_application_ifarh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4714a0fb-b62e-41ca-b28c-6982540bac34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM crm_ah.msdyn_purchaseorderproduct AS POP\n",
    "INNER JOIN crm_crosslob.cmhc_application_ifarh AS CP\n",
    "ON CP.id = POP.cmhc_application_ifarhid\n",
    "left join crm_ah.msdyn_purchaseorder PO\n",
    "on PO.id = POP.msdyn_purchaseorder;\n",
    "/*refer to RITM7157542_AliastoERPGSL_viaPOP_CPandFSlevelJoiner.txt*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4918a6a-edba-4af9-bcd2-a6345ad819bb",
     "showTitle": true,
     "title": "Trail 1st: Use SQL"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT joined_data.cmhc_programidname, COUNT(*) AS count\n",
    "FROM (\n",
    "    SELECT PO.cmhc_internalponumber, CP.cmhc_programidname\n",
    "    FROM crm_ah.msdyn_purchaseorderproduct AS POP\n",
    "    INNER JOIN crm_crosslob.cmhc_application_ifarh AS CP\n",
    "    ON CP.id = POP.cmhc_application_ifarhid\n",
    "    LEFT JOIN crm_ah.msdyn_purchaseorder AS PO\n",
    "    ON PO.id = POP.msdyn_purchaseorder\n",
    "    WHERE PO.msdyn_approvalstatus_en IS NULL\n",
    ") AS joined_data\n",
    "GROUP BY joined_data.cmhc_programidname;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1daa463-971f-4f66-9228-c3238625bdb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "selected_column = _sqldf.select('joined_data.cmhc_programidname',\"count\")\n",
    "selected_column.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e545b4bd-1440-46b6-86a5-21ba8478d315",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pandas_df = _sqldf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87f0c634-cfc8-4d35-b082-c9897e018db6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3bf6307-930d-4d73-848b-0139a2190892",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#drop1 2 4 5 6 7 32 33 34 40\n",
    "rows_to_drop = [1, 2, 4, 5, 6, 7, 32, 33, 34, 40]\n",
    "pandas_df_dropped = pandas_df.drop(index=rows_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1568943-6cbc-4003-9203-d1e45309d030",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#keep only 12: On-Reserve Non Profit Housing Program  (Section 95)& drop rest section 95\n",
    "# Assuming pandas_df is your DataFrame\n",
    "rows_to_exclude = [12]\n",
    "keyword = 'Section 95'\n",
    "\n",
    "# Create a boolean mask for rows to exclude\n",
    "exclude_mask = (pandas_df_dropped.index.isin(rows_to_exclude)) | (pandas_df_dropped['cmhc_programidname'].str.contains(keyword))\n",
    "\n",
    "# Apply the mask and create a new DataFrame\n",
    "pandas_df_filtered = pandas_df_dropped[~exclude_mask]\n",
    "\n",
    "print(pandas_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8386660c-16cb-46f6-838e-9d4167ed5712",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"/Workspace/Users/zzhang@cmhc-schl.gc.ca/short program name.xlsx\"  # Update the folder path as per your directory structure\n",
    "SN = pd.read_excel(folder_path,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4126945f-3a06-47b5-b184-800663c2bf04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "525b0d54-fc74-4f40-b169-8638c80ab2c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(SN, pandas_df_filtered, on='cmhc_programidname', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0a9f946-41be-4813-bbe2-8cd1389efe98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf970111-6c3b-4ddc-ac56-f4482aaf6d8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_df['cmhc_programidname'] = merged_df['cmhc_programidname'].apply(lambda x: x.split(']', 1)[1] if ']' in x else x)\n",
    "merged_df['cmhc_programidname'] = merged_df['cmhc_programidname'].apply(lambda x: x.split('[', 1)[0] if '[' in x else x)\n",
    "merged_df['cmhc_programidname'] = merged_df['cmhc_programidname'].apply(lambda x: x.split('|', 1)[0] if '|' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3929a41f-ec30-40e6-a6be-aa17af66c948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b334aa2-c3c4-4d38-99c0-ea52c53e7371",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#uniform the program name\n",
    "merged_df['cmhc_programidname'] = merged_df['cmhc_programidname'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6149210-945a-41fd-9a77-8922b785869b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# Calculate confidence interval for predicted values\n",
    "confidence_level = 0.95\n",
    "degrees_freedom = len(y_test) - 1\n",
    "confidence_interval = stats.t.interval(confidence_level, degrees_freedom, loc=y_pred.mean(), scale=stats.sem(y_pred))\n",
    "\n",
    "print(f\"Confidence Interval for Predicted Values: {confidence_interval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c44daf24-700d-4106-94f6-60c067fe8cfe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_starting_with_program = [col for col in TS_f.columns if col.startswith(\"Program\")]\n",
    "columns_starting_with_program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2089fcf-7637-4a86-954c-f22e90116c84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_values_count = len(columns_starting_with_program)\n",
    "unique_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4965a20c-0d2e-4c89-baf8-8b6b456d626c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the columns for which you want to calculate confidence intervals\n",
    "columns_to_check = columns_starting_with_program\n",
    "\n",
    "# Calculate confidence intervals for each column where the instance equals 1\n",
    "confidence_level = 0.95\n",
    "degrees_freedom = len(y_test) - 1\n",
    "confidence_intervals = []\n",
    "\n",
    "for column in columns_to_check:\n",
    "    indices = np.where(X[column] == True)\n",
    "    pred_values = y_pred_all[indices]\n",
    "    interval = stats.t.interval(confidence_level, degrees_freedom, loc=pred_values.mean(), scale=stats.sem(pred_values))\n",
    "    confidence_intervals.append({'Column': column, 'Confidence Interval': interval})\n",
    "    \n",
    "confidence_df = pd.DataFrame(confidence_intervals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "102de876-1e99-4c18-b664-a54bbb327b55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_values_count = TS_c['Program:'].nunique()\n",
    "unique_values_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fc1cd27-c828-47e8-bc24-6538cf93a5de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confidence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cfdf0bb-46c8-4c12-84e7-c78cae4afc36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confidence_df['Column'] = confidence_df['Column'].str.split('_', n=1).str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c21c52b-8335-45a4-bdfb-c197918c1286",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dda656f-a79a-481d-8a30-5d11bf4445ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Function to calculate similarity score between two strings\n",
    "def calculate_similarity(str1, str2):\n",
    "    return fuzz.ratio(str1, str2)\n",
    "\n",
    "# Set the similarity threshold\n",
    "similarity_threshold = 40\n",
    "\n",
    "# Create an empty list to store the matching rows\n",
    "matched_rows = []\n",
    "\n",
    "# Iterate through each pair of values from the two DataFrames\n",
    "for value_df1 in confidence_df['Column']:\n",
    "    for value_df2 in merged_df['cmhc_programidname']:\n",
    "        similarity_score = calculate_similarity(value_df1, value_df2)\n",
    "        if similarity_score >= similarity_threshold:\n",
    "            matched_rows.append({'Programs_Actual': value_df1, 'Programs_Predict': value_df2, 'similarity_score': similarity_score})\n",
    "\n",
    "# Create a DataFrame from the list of matched rows\n",
    "matched_df = pd.DataFrame(matched_rows)\n",
    "\n",
    "# Merge the matched DataFrame with the original DataFrames\n",
    "df_1 = pd.merge(matched_df, confidence_df, how='left', left_on='Programs_Actual', right_on='Column')\n",
    "df_2 = pd.merge(df_1,merged_df, how='left', left_on='Programs_Predict', right_on='cmhc_programidname')\n",
    "\n",
    "print(df_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d71f22-a673-4aa1-bb3f-38316f73a760",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc232766-9cc3-4f34-b910-504b8853edfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2 = df_2.dropna(subset=['Program Short Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "122bf9ea-34b5-4983-93f4-f42212f9ec49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the index of the row with the highest similarity score for each group\n",
    "idx_to_keep = df_2.groupby('Column')['similarity_score'].idxmax()\n",
    "\n",
    "# Keep only the rows with the maximum similarity score for each group\n",
    "result_df = df_2.loc[idx_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "516245f0-b76f-47a4-9304-42a9c1951b92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_values_count = result_df['Column'].nunique()\n",
    "unique_values_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c479cb5-3e44-4b9a-8dc2-e3b91aa75c54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df.rename(columns={'count': 'Total Number of PO'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf79979c-703a-42fb-bfc4-9dc15efdc408",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c542175-0fc5-4dc5-a9b9-f67a03cd2986",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confidence_df = result_df.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba86bfa0-3f30-425d-858a-031044bff4e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff09fe84-e384-4c8c-a18f-1f4d3138ea5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "indexes_to_replace = [7, 17,25, 37]\n",
    "new_values_program_short_name = [\"Indigenous Shelters\", \"Preservation\", \"RHI1\", \"RHI3\"]\n",
    "new_values_count = [7,1302,146,146]\n",
    "\n",
    "result_df.loc[indexes_to_replace, \"Program Short Name\"] = new_values_program_short_name\n",
    "result_df.loc[indexes_to_replace, \"Total Number of PO\"] = new_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a53e3d55-6275-4b06-b36b-71dd46c28261",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddce4b35-0f54-49f8-acdb-624c32e6477a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confidence_df = result_df.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab407c5-5ced-48d8-81ae-cab058dd1d84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confidence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d074f21-dfb0-4459-a52f-eb3a603d2126",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "for index, row in confidence_df.iterrows():\n",
    "    num_values = row[\"Total Number of PO\"]\n",
    "    confidence_interval = row[\"Confidence Interval\"]\n",
    "    random_values = [random.uniform(confidence_interval[0], confidence_interval[1]) for _ in range(num_values)]\n",
    "    new_column_names = [f\"Random_{i}\" for i in range(1, num_values + 1)]\n",
    "    confidence_df.loc[index, new_column_names] = random_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2db3fa88-e949-4ad3-b420-5e49801cdb0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confidence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82d67212-a31b-47c0-b2d9-760c02b6425d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_loop1 = confidence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a573eb98-8529-41e9-b1cd-996df1698afa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_loop1[\"Average_Random\"] = df_loop1.iloc[:, 4:].mean(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea843dab-5961-4756-8557-40308b2a0d9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_loop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c70e6705-fb23-414c-94b6-198af4fc535e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select the desired columns\n",
    "columns_to_keep = [\"Column\",\"Total Number of PO\", \"Confidence Interval\", \"Average_Random\",\"Program Short Name\"]\n",
    "df_loop1 = df_loop1[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bf2f9f0-0bce-45aa-a29b-dc42f3241c2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_loop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7106c026-5d7a-4b0b-ba5d-b407816dc26e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_loop1.reset_index(drop=True, inplace=True)\n",
    "#df_loop1.index = df_loop1.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6edf625e-47b3-440c-867e-58957b32d28e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_loop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aafbfad-3c79-4f0f-aca4-bbd90f4ed578",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_simulations = 1000\n",
    "average_values = []\n",
    "\n",
    "for index, row in df_loop1.iterrows():\n",
    "    num_values = row[\"Total Number of PO\"]\n",
    "    confidence_interval = row[\"Confidence Interval\"]\n",
    "    averages = []\n",
    "    \n",
    "    for _ in range(num_simulations):\n",
    "        random_values = [random.uniform(confidence_interval[0], confidence_interval[1]) for _ in range(num_values)]\n",
    "        average_random = sum(random_values) / num_values\n",
    "        averages.append(average_random)\n",
    "    \n",
    "    average_values.append(averages)\n",
    "\n",
    "# Convert average_values to a DataFrame\n",
    "average_df = pd.DataFrame(average_values)\n",
    "average_df.columns = [f\"Average_{i+1}\" for i in range(num_simulations)]\n",
    "\n",
    "# Concatenate average_df with the original DataFrame\n",
    "result_df = pd.concat([df_loop1, average_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "658ee20e-7817-4eab-8fef-0cf68f71ad4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9f9693f-a63b-461f-8403-08b6e8281460",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate random values within the interval and calculate averages\n",
    "num_simulations = 1000\n",
    "average_values = []\n",
    "\n",
    "for index, row in confidence_df.iterrows():\n",
    "    num_values = row[\"Total Number of PO\"]\n",
    "    confidence_interval = row[\"Confidence Interval\"]\n",
    "    averages = []\n",
    "    \n",
    "    for _ in range(num_simulations):\n",
    "        random_values = [random.uniform(confidence_interval[0], confidence_interval[1]) for _ in range(num_values)]\n",
    "        average_random = sum(random_values) / num_values\n",
    "        averages.append(average_random)\n",
    "    \n",
    "    average_values.append(averages)\n",
    "\n",
    "# Convert average_values to a DataFrame\n",
    "average_df = pd.DataFrame(average_values)\n",
    "average_df.columns = [f\"Average_{i+1}\" for i in range(num_simulations)]\n",
    "\n",
    "# Calculate confidence interval and mean for each row\n",
    "confidence_intervals = []\n",
    "means = []\n",
    "\n",
    "for index, row in average_df.iterrows():\n",
    "    data = row.values\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data, ddof=1)\n",
    "    margin_of_error = stats.t.ppf((1 + 0.95) / 2, df=num_simulations - 1) * (std_dev / np.sqrt(num_simulations))\n",
    "    confidence_interval = (mean - margin_of_error, mean + margin_of_error)\n",
    "    means.append(mean)\n",
    "    confidence_intervals.append(confidence_interval)\n",
    "\n",
    "# Add mean and confidence interval columns to the result_df\n",
    "result_df[\"Mean(mins)\"] = means\n",
    "result_df[\"Confidence_Interval_final\"] = confidence_intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b316682e-6c96-43f7-acaa-a7243a2e009a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cdb9abe-820a-495f-b31b-7d86dfb0617b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_keep = [\"Column\",'Program Short Name',\"Total Number of PO\", \"Confidence_Interval_final\",\"Mean(mins)\"]\n",
    "df = result_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeae6457-5de7-42b5-9943-b5134613af99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43778dcc-2a75-4228-b244-d26e64cc252c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[\"Total Processing Time(hrs)\"] = df[\"Total Number of PO\"] * df[\"Mean(mins)\"] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61311461-d46f-4f4f-8265-a73b5d8f3bff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91888c3b-64bc-4f0c-8d16-776fdb18a2e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['Confidence_Interval_final'] = df['Confidence_Interval_final'].apply(lambda x: (round(x[0], 2), round(x[1], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f1ce68f-c579-4f44-9856-4b5381e032ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'Column': 'Program',\n",
    "    'Total Number of PO': 'Total # of Unapproved PO of Each Program',\n",
    "    'Confidence_Interval_final': 'Confidence Interval of Average Processing Time of Each PO(Minutes)',\n",
    "    'Mean(mins)':\"Average Processing Time of Each PO(Minutes)\",\n",
    "    \"Total Processing Time(hrs)\":\"Total Processing Time of Each Program(Hours)\"\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75598e09-7479-4e94-a2ad-5b5d8cae2212",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d6ef99d-caf1-4d0d-b983-670770ce2dc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "830bb39b-7a30-41a9-9697-b6504ff46912",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop the specified column\n",
    "df.drop('Confidence Interval of Average Processing Time of Each PO(Minutes)', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4f42535-8ba7-4d58-ba6d-8d3dfacce392",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.iteritems = pd.DataFrame.items\n",
    "from pyspark.sql import SparkSession\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# Assuming 'pandas_df' is your Pandas DataFrame\n",
    "spark_df = spark.createDataFrame(df)\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef795253-f0d1-41a4-93ad-ff9075804893",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "2d2ad5c6-9cb2-473d-a9e6-37cdd4bccc25",
     "origId": 0,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    },
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "fb0ab7a5-6478-4b30-925e-2161944395dd",
     "origId": 0,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    },
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "a5bb04c3-a5de-4175-a4b5-223bb03d646f",
       "elementType": "command",
       "guid": "a43c192f-e3c1-494d-bf7e-7f446753a4e9",
       "options": null,
       "position": {
        "height": 23,
        "width": 24,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "27b22598-b1ec-4a66-8df1-897bd6e3d3ca",
     "origId": 0,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    },
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "c0a9f946-41be-4813-bbe2-8cd1389efe98",
       "elementType": "command",
       "guid": "20b4e990-f05e-485c-b2ed-ab269cca8c55",
       "options": null,
       "position": {
        "height": 21,
        "width": 24,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "b80c0cc7-cfab-4ec0-a56f-4b2db3020d29",
     "origId": 0,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2165741003912609,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Task 7 Complete (2)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
